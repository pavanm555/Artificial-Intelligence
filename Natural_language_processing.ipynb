{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/3T2I/nTbeJkfldxFaOu+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavanm555/Artificial-Intelligence/blob/main/Natural_language_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4URe9A_APPD",
        "outputId": "c9c7b0b3-8837-4044-f078-390333c5308f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# Importing required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download(\"wordnet\")\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello! How are you today? I'm excited to work on natural language processing tasks! #NLP #MachineLearning\"\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KzPyPDzmAZDP",
        "outputId": "e79a4e23-8ea5-4d82-e76e-c28e18f82941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello! How are you today? I'm excited to work on natural language processing tasks! #NLP #MachineLearning\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps to perform NLP:\n",
        "#### 1) Remove the special characters.\n",
        "#### 2) Converting entire text to upper or lower case.\n",
        "#### 3) Split the data.\n",
        "#### 4) Remove stopwords.\n",
        "#### 5) Stemming / Lematization.\n",
        "#### 6) Join the words.\n",
        "#### 7) Convert text to numerical values.\n"
      ],
      "metadata": {
        "id": "o4YaW_DZA3WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Remove the special characters\n",
        "\n",
        "only_text = re.sub('[^a-zA-Z]',' ',text)\n",
        "only_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6X1EJGAxAZFj",
        "outputId": "c97a9750-f0eb-40bf-d748-1cc2bb1bbe88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello  How are you today  I m excited to work on natural language processing tasks   NLP  MachineLearning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Converting entire text to upper or lower case\n",
        "lowercase_text = only_text.lower()\n",
        "lowercase_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eSJrjzbhAZIa",
        "outputId": "b06ed777-5b1a-4433-963b-343ed44ef2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello  how are you today  i m excited to work on natural language processing tasks   nlp  machinelearning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Split the data\n",
        "text_split= lowercase_text.split()\n",
        "text_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FwpYEt3AZLA",
        "outputId": "2e868743-3e34-4c88-93bb-a82984b5a9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello',\n",
              " 'how',\n",
              " 'are',\n",
              " 'you',\n",
              " 'today',\n",
              " 'i',\n",
              " 'm',\n",
              " 'excited',\n",
              " 'to',\n",
              " 'work',\n",
              " 'on',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'tasks',\n",
              " 'nlp',\n",
              " 'machinelearning']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Remove stopwords\n",
        "stopwords = stopwords.words('english')\n",
        "no_stopwords_text = [word for word in text_split if word not in stopwords]\n",
        "no_stopwords_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up30ugJRAZNY",
        "outputId": "b6bfa368-346d-4527-b7c3-f3e2b20277c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello',\n",
              " 'today',\n",
              " 'excited',\n",
              " 'work',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'tasks',\n",
              " 'nlp',\n",
              " 'machinelearning']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Stemming / Lematization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "text_Lematization = [lemmatizer.lemmatize(word) for word in no_stopwords_text]\n",
        "text_Lematization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUCWJQzRAZQO",
        "outputId": "50c86b76-9537-402c-98b0-862ed5a95a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello',\n",
              " 'today',\n",
              " 'excited',\n",
              " 'work',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'task',\n",
              " 'nlp',\n",
              " 'machinelearning']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Join the words\n",
        "sentence = \" \".join(text_Lematization)\n",
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MG-R2BM4GO9i",
        "outputId": "db25c69d-da80-4e3f-c3f1-4605eb6b1fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello today excited work natural language processing task nlp machinelearning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7)Convert text to num\n",
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer.fit_transform([sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAla91bUGPEi",
        "outputId": "ad0ed242-919a-4d98-dde1-8164493cda94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x10 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 10 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "def nlp(text):\n",
        "  data = []\n",
        "  review = text\n",
        "  review = re.sub('[^a-zA-Z]',' ',review)\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [lemmatizer.lemmatize(word) for word in review if word not in stopwords]\n",
        "  review = ' '.join(review)\n",
        "  data.append(review)\n",
        "  print(\"Before CountVectorizer: \")\n",
        "  print(data)\n",
        "  data = count_vectorizer.fit_transform(data)\n",
        "  print(\"After CountVectorizer: \")\n",
        "  print(data)\n",
        "text = \"Hello! How are you today? I'm feeling great! #Excited\"\n",
        "\n",
        "nlp(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAVXD978GPHp",
        "outputId": "6a73c50a-786c-4004-a37f-8f70a32257aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before CountVectorizer: \n",
            "['hello today feeling great excited']\n",
            "After CountVectorizer: \n",
            "  (0, 3)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 1)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 0)\t1\n"
          ]
        }
      ]
    }
  ]
}